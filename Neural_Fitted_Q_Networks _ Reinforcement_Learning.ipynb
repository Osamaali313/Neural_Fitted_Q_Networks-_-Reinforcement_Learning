{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"L4","authorship_tag":"ABX9TyPikKBp8w1jTkbQFIpjFmH+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!pip install gymnasium"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ya8ivSwdXVSR","executionInfo":{"status":"ok","timestamp":1720459307309,"user_tz":-300,"elapsed":6964,"user":{"displayName":"Syed Ali","userId":"00026085019319269903"}},"outputId":"31c57549-486a-4554-9038-625e7a4a4df1"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting gymnasium\n","  Downloading gymnasium-0.29.1-py3-none-any.whl (953 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/953.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.3/953.9 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.9/953.9 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (1.25.2)\n","Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (2.2.1)\n","Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium) (4.12.2)\n","Collecting farama-notifications>=0.0.1 (from gymnasium)\n","  Downloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n","Installing collected packages: farama-notifications, gymnasium\n","Successfully installed farama-notifications-0.0.4 gymnasium-0.29.1\n"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F"],"metadata":{"id":"zcwTEK6yXLXN","executionInfo":{"status":"ok","timestamp":1720459351503,"user_tz":-300,"elapsed":4313,"user":{"displayName":"Syed Ali","userId":"00026085019319269903"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["torch.cuda.is_available()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xU-tTZCFXMdi","executionInfo":{"status":"ok","timestamp":1720459353872,"user_tz":-300,"elapsed":13,"user":{"displayName":"Syed Ali","userId":"00026085019319269903"}},"outputId":"54ca874f-c59c-4507-e81d-6d5d6ef9e539"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["import time\n","import random\n","\n","import numpy as np\n","import gymnasium as gym\n","import matplotlib.pyplot as plt\n","\n","from tqdm import tqdm\n","from itertools import count\n","\n","from IPython import display"],"metadata":{"id":"wpkthRfIXOSY","executionInfo":{"status":"ok","timestamp":1720459357569,"user_tz":-300,"elapsed":740,"user":{"displayName":"Syed Ali","userId":"00026085019319269903"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["class FCQ(nn.Module):\n","    def __init__(self, input_dim, output_dim, hidden_dims=(32, 32), activation_fc=F.relu):\n","        super(FCQ, self).__init__()\n","        self.activation_fc = activation_fc\n","        self.input_layer = nn.Linear(input_dim, hidden_dims[0])\n","        self.hidden_layers = nn.ModuleList()\n","        for i in range(len(hidden_dims) - 1):\n","            hidden_layer = nn.Linear(hidden_dims[i], hidden_dims[i+1])\n","            self.hidden_layers.append(hidden_layer)\n","        self.output_layer = nn.Linear(hidden_dims[-1], output_dim)\n","\n","        device = \"cpu\"\n","        if torch.cuda.is_available():\n","            device = \"cuda:0\"\n","        self.device = torch.device(device)\n","        self.to(self.device)\n","\n","    def _format(self, state):\n","        x = state\n","        if not isinstance(x, torch.Tensor):\n","            x = torch.tensor(x, device=self.device, dtype=torch.float32)\n","            x = x.unsqueeze(0)\n","        return x\n","\n","    def forward(self, state):\n","        x = self._format(state)\n","        x = self.activation_fc(self.input_layer(x))\n","        for hidden_layer in self.hidden_layers:\n","            x = self.activation_fc(hidden_layer(x))\n","        x = self.output_layer(x)\n","        return x\n","\n","    def numpy_float_to_device(self, variable):\n","        variable = torch.from_numpy(variable).float().to(self.device)\n","        return variable\n","\n","    def load(self, experiences):\n","        states, actions, rewards, new_states, is_terminals = experiences\n","        states = torch.from_numpy(states).float().to(self.device)\n","        actions = torch.from_numpy(actions).long().to(self.device)\n","        new_states = torch.from_numpy(new_states).float().to(self.device)\n","        rewards = torch.from_numpy(rewards).float().to(self.device)\n","        is_terminals = torch.from_numpy(is_terminals).float().to(self.device)\n","        return states, actions, rewards, new_states, is_terminals"],"metadata":{"id":"fWa2zdd7XRL4","executionInfo":{"status":"ok","timestamp":1720459360687,"user_tz":-300,"elapsed":5,"user":{"displayName":"Syed Ali","userId":"00026085019319269903"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["class GreedyStrategy():\n","    def __init__(self):\n","        pass\n","    def select_action(self, model, state):\n","        with torch.no_grad():\n","            q_values = model(state).cpu().detach().data.numpy().squeeze()\n","            return np.argmax(q_values)"],"metadata":{"id":"sbVy-HhuXoBv","executionInfo":{"status":"ok","timestamp":1720459458335,"user_tz":-300,"elapsed":1094,"user":{"displayName":"Syed Ali","userId":"00026085019319269903"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["class EGreedyStrategy():\n","    def __init__(self, epsilon=0.1):\n","        self.epsilon = epsilon\n","\n","    def select_action(self, model, state):\n","        with torch.no_grad():\n","            q_values = model(state).cpu().detach().data.numpy().squeeze()\n","\n","        if np.random.rand() > self.epsilon:\n","            action = np.argmax(q_values)\n","        else:\n","            action = np.random.randint(len(q_values))\n","        return action"],"metadata":{"id":"HJv0rXn1Xrbz","executionInfo":{"status":"ok","timestamp":1720459462944,"user_tz":-300,"elapsed":2,"user":{"displayName":"Syed Ali","userId":"00026085019319269903"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["class NFQ():\n","    def __init__(self, value_model_fn, value_optimizer_fn, value_optimizer_lr, training_strategy_fn, evaluation_strategy_fn, batch_size, epochs):\n","        self.value_model_fn = value_model_fn\n","        self.value_optimizer_fn = value_optimizer_fn\n","        self.value_optimizer_lr = value_optimizer_lr\n","        self.training_strategy_fn = training_strategy_fn\n","        self.evaluation_strategy_fn = evaluation_strategy_fn\n","        self.batch_size = batch_size\n","        self.epochs = epochs\n","\n","    def train(self, env, seed, gamma, max_episodes):\n","        self.gamma = gamma\n","        self.seed = seed\n","        torch.manual_seed(self.seed); np.random.seed(self.seed); random.seed(self.seed)\n","\n","        nS, nA = env.observation_space.shape[0], env.action_space.n\n","\n","        self.online_model = self.value_model_fn(nS, nA)\n","        self.value_optimizer = self.value_optimizer_fn(self.online_model, self.value_optimizer_lr)\n","        self.training_stategy = training_strategy_fn()\n","        self.evaluation_strategy = evaluation_strategy_fn()\n","        self.experiences = []\n","\n","        result = np.empty((max_episodes, 5))\n","        result[:] = np.nan\n","        training_time = 0\n","\n","        for episode in tqdm(range(1, max_episodes + 1), leave=True):\n","            state, info = env.reset()\n","            for step in count():\n","                state, is_terminal = self.interaction_step(state, env)\n","\n","                if len(self.experiences) >= self.batch_size:\n","                    experiences = np.array(self.experiences, dtype=object)\n","                    batches = [np.vstack(sars) for sars in experiences.T]\n","                    experiences = self.online_model.load(batches)\n","\n","                    for _ in range(self.epochs):\n","                        self.optimize_model(experiences)\n","                    self.experiences.clear()\n","\n","                if is_terminal:\n","                    break\n","\n","        rewards, final_eval_score, score_std = self.evaluate(self.online_model, env, n_episodes=100)\n","        env.close()\n","        print(\"Training Complete\")\n","        print(f\"Final evaluation score: {final_eval_score:.2f} -+ ScoreSTD: {score_std:.2f}\")\n","        return final_eval_score\n","\n","\n","    def interaction_step(self, state, env):\n","        action = self.training_stategy.select_action(self.online_model, state)\n","        next_state, reward, is_terminal, is_truncated, info = env.step(action)\n","        is_failure = is_terminal and not is_truncated\n","        experience = (state, action, reward, next_state, float(is_failure))\n","        self.experiences.append(experience)\n","\n","        return next_state, (is_terminal or is_truncated)\n","\n","    def optimize_model(self, experiences):\n","        states, actions, rewards, next_states, is_terminals = experiences\n","        batch_size = len(is_terminals)\n","\n","        # Get the best action of the next state\n","        best_action_Q_next_state = self.online_model(next_states).detach().max(1)[0].unsqueeze(1)\n","        target_q_state = rewards + self.gamma * best_action_Q_next_state * (1 - is_terminals)\n","        # Get current estimate of Q(s, a)\n","        q_sa = self.online_model(states).gather(1, actions)\n","\n","        td_errors = q_sa - target_q_state\n","        # MSE Loss\n","        value_loss = td_errors.pow(2).mul(0.5).mean()\n","\n","        self.value_optimizer.zero_grad()\n","        value_loss.backward()\n","        self.value_optimizer.step()\n","\n","    def evaluate(self, eval_policy_model, eval_env, n_episodes=1):\n","        rewards = []\n","        for _ in tqdm(range(n_episodes), leave=True):\n","            state, info = eval_env.reset()\n","            rewards.append(0)\n","            for _ in count():\n","                action = self.evaluation_strategy.select_action(eval_policy_model, state)\n","                state, reward, is_terminal, is_truncated, info = eval_env.step(action)\n","                rewards[-1] += reward\n","                if (is_terminal or is_truncated):\n","                    break\n","        return rewards, np.mean(rewards), np.std(rewards)"],"metadata":{"id":"9qQsXZZaXt1R","executionInfo":{"status":"ok","timestamp":1720459508522,"user_tz":-300,"elapsed":860,"user":{"displayName":"Syed Ali","userId":"00026085019319269903"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["env = gym.make(\"CartPole-v1\")"],"metadata":{"id":"ZSy7xHCmYLiX","executionInfo":{"status":"ok","timestamp":1720459557420,"user_tz":-300,"elapsed":648,"user":{"displayName":"Syed Ali","userId":"00026085019319269903"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["value_model_fn = lambda nS, nA: FCQ(nS, nA, hidden_dims=(512, 128))\n","value_optimizer_fn = lambda net, lr: torch.optim.RMSprop(net.parameters(), lr=lr)\n","value_optimizer_lr = 0.0005\n","\n","training_strategy_fn = lambda: EGreedyStrategy(epsilon=0.5)\n","evaluation_strategy_fn = lambda: GreedyStrategy()\n","\n","batch_size = 1024\n","epochs = 40\n","\n","agent = NFQ(value_model_fn, value_optimizer_fn, value_optimizer_lr, training_strategy_fn, evaluation_strategy_fn, batch_size, epochs)\n","final_eval_score = agent.train(env, seed=90, gamma=1.00, max_episodes=5000)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o7kxa67kYS6K","executionInfo":{"status":"ok","timestamp":1720459834095,"user_tz":-300,"elapsed":273517,"user":{"displayName":"Syed Ali","userId":"00026085019319269903"}},"outputId":"71159bb8-98e6-4f77-e75d-244dfb132f05"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 5000/5000 [04:17<00:00, 19.40it/s]\n","100%|██████████| 100/100 [00:14<00:00,  7.08it/s]"]},{"output_type":"stream","name":"stdout","text":["Training Complete\n","Final evaluation score: 489.19 -+ ScoreSTD: 21.03\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]}]}